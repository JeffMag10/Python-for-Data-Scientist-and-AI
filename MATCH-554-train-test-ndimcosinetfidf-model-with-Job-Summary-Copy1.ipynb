{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds upon what Tom McTavish accomplished.  The acceptance criteria is\n",
    "\n",
    "        Append Job Description for Job Summary\n",
    "        Retrain Unsupervised Model\n",
    "        Compare Accuracy to Previous Version\n",
    "\n",
    "This notebook builds, tests, and profiles the unsupervised NDimCosineTfidf (N-Dimensional Cosine TF-IDF) model for eFC. If running the whole notebook, this takes about an hour to run. \n",
    "\n",
    "\n",
    "\n",
    "**Author:** Tom McTavish\n",
    "**Update by:** Jeff Magouirk\n",
    "\n",
    "**Date:** July 22, 2020\n",
    "**Date of update:** September 2, 2020\n",
    "\n",
    "**Confluence Page - https://confluence.dhigroupinc.com/display/MATCH/MATCH-554-prototype-job-summary-job-desc\n",
    "\n",
    "**Training Data:** Live-Feed CSV files from February - Mid July, 2020.\n",
    "**New Training Data:** Live-Feed CSV files from February 8, 2020 - August 26, 2020.\n",
    "\n",
    "* s3://dev-dhi-match-datascience/data/efc/live-feed/raw-2020<02-0826>.csv\n",
    "  \n",
    "\n",
    "  \n",
    "**Testing Data:**\n",
    " \n",
    "  * s3://dev-dhi-match-datascience/data/efc/train_test_20200716.csv\n",
    "  * s3://dev-dhi-match-datascience/data/efc/Validation/train_test_with_jobsummary_09012020.cs\n",
    "  \n",
    "**Main Model Source:**\n",
    "\n",
    "  Bitbucket: [dhi-match-datascience/dsmatch/sklearnmodeling/models/ndimcostfidf.py](https://bitbucket.org/dhigroupinc/dhi-match-datascience/src/MATCH-484-package-unsupervised-tfidf-mod/dsmatch/sklearnmodeling/models/ndimcostfidf.py)\n",
    "  \n",
    "**Model File Output:** s3://dev-dhi-match-datascience/models/efc/unsupervised/twodimcostfidf-20200722.joblib\n",
    "**Combined Feature - Model File Output:** s3://dev-dhi-match-datascience/models/efc/unsupervised/twodimcostfidf-20200828.joblib\n",
    "\n",
    "**JIRA:** [MATCH-484](https://jira.dhigroupinc.com/browse/MATCH-484)\n",
    "**JIRA:** https://jira.dhigroupinc.com/browse/MATCH-554"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-20.2.3-py2.py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 14.0 MB/s eta 0:00:01     |██████████████████▎             | 860 kB 14.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.0.2\n",
      "    Uninstalling pip-20.0.2:\n",
      "      Successfully uninstalled pip-20.0.2\n",
      "Successfully installed pip-20.2.3\n",
      "Collecting contractions\n",
      "  Downloading contractions-0.0.25-py2.py3-none-any.whl (3.2 kB)\n",
      "Collecting textsearch\n",
      "  Downloading textsearch-0.0.17-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting Unidecode\n",
      "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
      "\u001b[K     |████████████████████████████████| 238 kB 18.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyahocorasick\n",
      "  Downloading pyahocorasick-1.4.0.tar.gz (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 35.2 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=87478 sha256=a19f2e2dee19261997f787b3c29f0565ebc1a209e740e6f1b4ddd60ae84b58f6\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/16/ec/84/27daa7f8d8c0bdad46f462e2834faa13cfda30ea07097e0e3d\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: Unidecode, pyahocorasick, textsearch, contractions\n",
      "Successfully installed Unidecode-1.1.1 contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n",
      "Collecting line-profiler\n",
      "  Downloading line_profiler-3.0.2-cp36-cp36m-manylinux2010_x86_64.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 6.6 MB/s  eta 0:00:01:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: IPython in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from line-profiler) (7.13.0)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from IPython->line-profiler) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from IPython->line-profiler) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from IPython->line-profiler) (0.15.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from IPython->line-profiler) (46.1.3.post20200330)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from IPython->line-profiler) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from IPython->line-profiler) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from IPython->line-profiler) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from IPython->line-profiler) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from IPython->line-profiler) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->IPython->line-profiler) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.5.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jedi>=0.10->IPython->line-profiler) (0.5.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from traitlets>=4.2->IPython->line-profiler) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from traitlets>=4.2->IPython->line-profiler) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->line-profiler) (0.1.9)\n",
      "Installing collected packages: line-profiler\n",
      "Successfully installed line-profiler-3.0.2\n",
      "Collecting joblib\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "\u001b[K     |████████████████████████████████| 300 kB 14.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: joblib\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 0.14.1\n",
      "    Uninstalling joblib-0.14.1:\n",
      "      Successfully uninstalled joblib-0.14.1\n",
      "Successfully installed joblib-0.16.0\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn) (0.16.0)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.23.1\n",
      "    Uninstalling scikit-learn-0.23.1:\n",
      "      Successfully uninstalled scikit-learn-0.23.1\n",
      "Successfully installed scikit-learn-0.23.2\n"
     ]
    }
   ],
   "source": [
    "### Run the uncommented pip installs first this should allow the whole notebook\n",
    "### This will allow the import below to run\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade contractions\n",
    "!pip install --upgrade line-profiler\n",
    "\n",
    "# !pip install --upgrade tqdm\n",
    "!pip install --upgrade joblib\n",
    "# !conda update numpy --yes\n",
    "# !conda remove scikit-learn --yes\n",
    "!pip install --upgrade scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import joblib\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "from bs4 import BeautifulSoup  ###Added by Jeff Magouirk - 8/31/2020\n",
    "\n",
    "from dsmatch.sklearnmodeling.models.ndimcostfidf import NDimCosTfidf\n",
    "from dsmatch.analytics.modelevaluation import labeled_xtab, aggregate_stats_from_xtab, print_aggregate_stats\n",
    "from dsmatch.analytics.modelevaluation import print_timing_performance, profile, profile_transform, profile_predict\n",
    "from dsmatch import local_bucket, s3_ds_bucket\n",
    "from dsmatch.util.io import read_csv\n",
    "from dsmatch.util.s3 import list_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set io parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subpath = os.path.join('data', 'efc', 'live-feed')\n",
    "\n",
    "model_name_0 = 'twodimcostfidf-20200908_0' ###creating a model with the original form of the data\n",
    "model_name = 'twodimcostfidf-20200908'  ###creating a new model, due to form of the data\n",
    "model_subpath = os.path.join('models', 'efc', 'unsupervised')\n",
    "cache_location = os.path.join(local_bucket, model_subpath, 'cache')\n",
    "data_out_path = os.path.join(local_bucket, data_subpath)\n",
    "model_profilerpath_0 = os.path.join(local_bucket, model_subpath, model_name_0+'_timings.txt')\n",
    "model_profilerpath = os.path.join(local_bucket, model_subpath, model_name+'_timings.txt')\n",
    "try:\n",
    "    os.makedirs(os.path.join(local_bucket, model_subpath))\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data.\n",
    "\n",
    "We obtain the list of files from our s3 bucket. Note that as `raw-YYYYMM.csv` files are added to our bucket, we add more training data. Therefore, updating the model only requires running this notebook again.  This data is a from the live feed data from February 8, 2020 to August 26, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_object_list = list_files(prefix=data_subpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/efc/live-feed/raw-202002.csv',\n",
       " 'data/efc/live-feed/raw-202003.csv',\n",
       " 'data/efc/live-feed/raw-202004.csv',\n",
       " 'data/efc/live-feed/raw-202005.csv',\n",
       " 'data/efc/live-feed/raw-202006.csv',\n",
       " 'data/efc/live-feed/raw-202007.csv',\n",
       " 'data/efc/live-feed/raw-20200826.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = [f for f in bucket_object_list if f.find('raw-') >= 0 and f.endswith('.csv')]\n",
    "csv_files = csv_files[0:]  # Last 3 months/data files. More than this and we run out of memory.  \n",
    "print('Training files:')\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read each of the csv files into a dictionary of DataFrames, including only the columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['resume', 'job.data.description', 'job.data.title','job.data.summary',\n",
    "        'date_retrieved','Language_JD','Language_Resume']  ##change by jeff added the job.data.summary field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Bringing in the data</h3>\n",
    "\n",
    "This can be a dynamic file depending on the amount of live feed data available<br>\n",
    "The sampling method will allow for additional data and will also allow for<br>\n",
    "the same sample to be taken every time.<br>\n",
    "<i>The records that are wanted are those resumes and job descriptions that are both in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a984efecbe84226ad2e03844f179b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows: 427000\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "pbar = tqdm(csv_files)\n",
    "for csv_file in pbar:\n",
    "    k = csv_file.split('/')[-1].split('.csv')[0]\n",
    "    pbar.set_description(k)\n",
    "    df = read_csv(data_subpath, k + '.csv')\n",
    "    df = df[cols]\n",
    "    df = df[(df['Language_JD']=='en') & (df['Language_Resume']=='en')]\n",
    "    df = df.drop(['Language_JD','Language_Resume'],axis=1)\n",
    "    # Random seed is the month (or last digits) of the file. This approach allows us to\n",
    "    # capture the specific sample again, if we want.\n",
    "    rs = int(csv_file.split('2020')[-1].split('.csv')[0])\n",
    "    df = df.sample(n=61_000, random_state=rs)\n",
    "    df = df.fillna('')\n",
    "    dfs[k] = df\n",
    "df = pd.concat(dfs.values(), ignore_index=True)\n",
    "print(f'Number of rows: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 427000 entries, 0 to 426999\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   resume                427000 non-null  object\n",
      " 1   job.data.description  427000 non-null  object\n",
      " 2   job.data.title        427000 non-null  object\n",
      " 3   job.data.summary      427000 non-null  object\n",
      " 4   date_retrieved        427000 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Combining the 'job.data.description' and 'job.data.summary' together </h3>\n",
    "<br><h4>Taking a 427,000 sample to allow for memory issues</h4> \n",
    "<br><h4>df_0 is the original dataset without the combined job.data.description and job.data.summary</h4>\n",
    "<br><h4>df is the dataset with the combined job.data.description and job.data.summary</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Original dataset with new sample of 427,000 records training data</i> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 427000 entries, 0 to 426999\n",
      "Data columns (total 3 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   resume                427000 non-null  object\n",
      " 1   job.data.description  427000 non-null  object\n",
      " 2   job.data.title        427000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 9.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume</th>\n",
       "      <th>job.data.description</th>\n",
       "      <th>job.data.title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reach Me at\\r\\n JASIM KOTTAKKARANTAVIDA Mob: ...</td>\n",
       "      <td>&lt;p&gt;As an Accountant, you will report to the Ac...</td>\n",
       "      <td>Accountant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Georges E. Kairouz \\r\\n\\r\\nDate of birth: 05/0...</td>\n",
       "      <td>&lt;p&gt;We are a leading Banking Group headquartere...</td>\n",
       "      <td>Investment Banking Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SONAL NAGPAL, CFA \\r\\n Email: nagpalsonal89@g...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; ...</td>\n",
       "      <td>Real Estate Portfolio Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAYO KOKU\\r\\nMobile Phone: - 07590 535685\\r\\nE...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Client&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;My client a ...</td>\n",
       "      <td>Quantitative Analyst - C#, FRTB, DRC, IRC, VAR,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kush Chowdhary - CURRICULUM VITAE\\r\\n\\r\\nMobil...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Business Development Manager – Sale...</td>\n",
       "      <td>Business Development Manager – Sales, Finance,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              resume  \\\n",
       "0   Reach Me at\\r\\n JASIM KOTTAKKARANTAVIDA Mob: ...   \n",
       "1  Georges E. Kairouz \\r\\n\\r\\nDate of birth: 05/0...   \n",
       "2   SONAL NAGPAL, CFA \\r\\n Email: nagpalsonal89@g...   \n",
       "3  MAYO KOKU\\r\\nMobile Phone: - 07590 535685\\r\\nE...   \n",
       "4  Kush Chowdhary - CURRICULUM VITAE\\r\\n\\r\\nMobil...   \n",
       "\n",
       "                                job.data.description  \\\n",
       "0  <p>As an Accountant, you will report to the Ac...   \n",
       "1  <p>We are a leading Banking Group headquartere...   \n",
       "2  <p><strong>Responsibilities</strong></p> <ul> ...   \n",
       "3  <p><strong>Client</strong></p> <p>My client a ...   \n",
       "4  <p><strong>Business Development Manager – Sale...   \n",
       "\n",
       "                                      job.data.title  \n",
       "0                                         Accountant  \n",
       "1                         Investment Banking Analyst  \n",
       "2                   Real Estate Portfolio Management  \n",
       "3    Quantitative Analyst - C#, FRTB, DRC, IRC, VAR,  \n",
       "4  Business Development Manager – Sales, Finance,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df\n",
    "df_0 = df_0[['resume','job.data.description','job.data.title']]\n",
    "#df_0 = df_0.rename(columns={'job.data.description':'job_description','job.data.title':'job_title'})\n",
    "print(df_0.info())\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Creating the dataframe of the combined fields of job.data.description and job.data.summary\n",
    "<br> with the 427,000 record dataset </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume</th>\n",
       "      <th>job.data.description</th>\n",
       "      <th>job.data.title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reach Me at\\r\\n JASIM KOTTAKKARANTAVIDA Mob: ...</td>\n",
       "      <td>&lt;p&gt;As an Accountant, you will report to the Ac...</td>\n",
       "      <td>Accountant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Georges E. Kairouz \\r\\n\\r\\nDate of birth: 05/0...</td>\n",
       "      <td>&lt;p&gt;We are a leading Banking Group headquartere...</td>\n",
       "      <td>Investment Banking Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SONAL NAGPAL, CFA \\r\\n Email: nagpalsonal89@g...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; ...</td>\n",
       "      <td>Real Estate Portfolio Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAYO KOKU\\r\\nMobile Phone: - 07590 535685\\r\\nE...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Client&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;My client a ...</td>\n",
       "      <td>Quantitative Analyst - C#, FRTB, DRC, IRC, VAR,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kush Chowdhary - CURRICULUM VITAE\\r\\n\\r\\nMobil...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Business Development Manager – Sale...</td>\n",
       "      <td>Business Development Manager – Sales, Finance,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              resume  \\\n",
       "0   Reach Me at\\r\\n JASIM KOTTAKKARANTAVIDA Mob: ...   \n",
       "1  Georges E. Kairouz \\r\\n\\r\\nDate of birth: 05/0...   \n",
       "2   SONAL NAGPAL, CFA \\r\\n Email: nagpalsonal89@g...   \n",
       "3  MAYO KOKU\\r\\nMobile Phone: - 07590 535685\\r\\nE...   \n",
       "4  Kush Chowdhary - CURRICULUM VITAE\\r\\n\\r\\nMobil...   \n",
       "\n",
       "                                job.data.description  \\\n",
       "0  <p>As an Accountant, you will report to the Ac...   \n",
       "1  <p>We are a leading Banking Group headquartere...   \n",
       "2  <p><strong>Responsibilities</strong></p> <ul> ...   \n",
       "3  <p><strong>Client</strong></p> <p>My client a ...   \n",
       "4  <p><strong>Business Development Manager – Sale...   \n",
       "\n",
       "                                      job.data.title  \n",
       "0                                         Accountant  \n",
       "1                         Investment Banking Analyst  \n",
       "2                   Real Estate Portfolio Management  \n",
       "3    Quantitative Analyst - C#, FRTB, DRC, IRC, VAR,  \n",
       "4  Business Development Manager – Sales, Finance,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_description'] = df['job.data.description'] + ' ' + df['job.data.summary']\n",
    "df_1 = df[['resume','job.data.description','job.data.title']]\n",
    "\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train the model.\n",
    "\n",
    "This has a few parts to it:\n",
    "\n",
    "  1. Preprocessing the data by cleaning and stemming it.  # Takes a while, but provides status bars\n",
    "  2. Training the TfidfVectorizer.  # Takes a while and does not provide a status.\n",
    "  3. Calculating the cosine similarities and setting the thresholds.  # Pretty fast, but no status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 427000 entries, 0 to 426999\n",
      "Data columns (total 3 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   resume                427000 non-null  object\n",
      " 1   job.data.description  427000 non-null  object\n",
      " 2   job.data.title        427000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456809516e3d46239f27d70b1e3a0a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='coupling job.data.title-job.data.description', max=150.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done training the model.\n"
     ]
    }
   ],
   "source": [
    "model = NDimCosTfidf(memory=cache_location)\n",
    "model.fit_transform(df_0)\n",
    "df_0 = None # Try to free up memory\n",
    "print('Done training the model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Model with combined job description and job summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324b90a5e8dc4b21a04f2f8fb9c7c573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='coupling job.data.title-job.data.description', max=150.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done training the model.\n"
     ]
    }
   ],
   "source": [
    "model = NDimCosTfidf(memory=cache_location)\n",
    "model.fit_transform(df_1)\n",
    "df_1 = None # Try to free up memory\n",
    "print('Done training the model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the model file and upload to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/SageMaker/shared/models/efc/unsupervised/twodimcostfidf-20200908_0.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#key = os.path.join(model_subpath, model_name + '.joblib')\n",
    "#joblib.dump(model, os.path.join(local_bucket, key))\n",
    "\n",
    "key = os.path.join(model_subpath, model_name + '.joblib')\n",
    "joblib.dump(model, os.path.join(local_bucket, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(s3_ds_bucket).Object(key).upload_file(os.path.join(local_bucket, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And dump the tfidf vectorizer as a separate model, too.\n",
    "key = os.path.join(model_subpath, 'onegram-tfidfvectorizer-20200908.joblib')\n",
    "joblib.dump(model.vectorizer, os.path.join(local_bucket, key))\n",
    "boto3.Session().resource('s3').Bucket(s3_ds_bucket).Object(key).upload_file(os.path.join(local_bucket, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "## Read the model from the s3 bucket, as if we were starting completely fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/efc/unsupervised/twodimcostfidf-20200908_0.joblib\n"
     ]
    }
   ],
   "source": [
    "# Original Model\n",
    "# https://stackoverflow.com/a/59903472/394430\n",
    "\n",
    "model_name = 'twodimcostfidf-20200908_0' ##Original model\n",
    "key  = os.path.join(model_subpath, model_name + '.joblib')\n",
    "print(key)\n",
    "from io import BytesIO\n",
    "\n",
    "with BytesIO() as data:\n",
    "    boto3.resource('s3').Bucket(s3_ds_bucket).download_fileobj(key, data)\n",
    "    data.seek(0)    # move back to the beginning after writing\n",
    "    model = joblib.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/efc/unsupervised/twodimcostfidf-20200908.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator QuantileTransformer from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in test data and run it through the model, evaluating accuracy.\n",
    "First model is against the new validated dataset, with the combined job description and job summery fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 533 entries, 0 to 532\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   match_score              533 non-null    float64\n",
      " 1   job_description_clean    533 non-null    object \n",
      " 2   resume_clean             533 non-null    object \n",
      " 3   job_title_clean          533 non-null    object \n",
      " 4   current_job_title_clean  533 non-null    object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 20.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 533 entries, 0 to 532\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   match_score      533 non-null    float64\n",
      " 1   job_description  533 non-null    object \n",
      " 2   resume           533 non-null    object \n",
      " 3   job_title        533 non-null    object \n",
      " 4   combined         533 non-null    int64  \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 20.9+ KB\n"
     ]
    }
   ],
   "source": [
    "## Model with combined job summary and job description.\n",
    "## 533 records\n",
    "## This variable is job_description_clean\n",
    "cols =['resume','job_description','job_title']\n",
    "df_scored = read_csv(os.path.join('data', 'efc','Validated'), 'train_test_with_jobsummary_09012020.csv')\n",
    "df_scored.info(verbose=True)\n",
    "df_scored = df_scored.rename(columns={'resume_clean':'resume','job_description_clean':'job_description',\n",
    "                                      'job_title_clean':'job_title'})\n",
    "df_scored = df_scored.drop('current_job_title_clean',axis=1)\n",
    "df_scored['combined'] = 1\n",
    "df_scored.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1033 entries, 0 to 1032\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   match_score            1033 non-null   float64\n",
      " 1   job_description_clean  1033 non-null   object \n",
      " 2   resume                 1033 non-null   object \n",
      " 3   job_title              1033 non-null   object \n",
      " 4   Combined1              1033 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 40.5+ KB\n"
     ]
    }
   ],
   "source": [
    "### Original 1033 dataset\n",
    "df_scored_0 = read_csv(os.path.join('data', 'efc'), 'train_test_20200716.csv')\n",
    "df_scored_0 = df_scored_0[['match_score','job_description_clean','resume_clean','job_title_clean']]\n",
    "df_scored_0 = df_scored_0.rename(columns={'resume_clean':'resume','job_title_clean':'job_title'})\n",
    "df_scored_0['Combined1'] = 0\n",
    "df_scored_0.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the original validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 533 entries, 0 to 532\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   match_score            533 non-null    float64\n",
      " 1   job_description        533 non-null    object \n",
      " 2   resume                 533 non-null    object \n",
      " 3   job_title              533 non-null    object \n",
      " 4   combined               533 non-null    int64  \n",
      " 5   job_description_clean  533 non-null    object \n",
      " 6   Combined1              533 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_scored_00 = df_scored.merge(df_scored_0,on=['resume','job_title','match_score'], how='left')\n",
    "df_scored_00.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 533 entries, 0 to 532\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   match_score            533 non-null    float64\n",
      " 1   job_description        533 non-null    object \n",
      " 2   resume                 533 non-null    object \n",
      " 3   job_title              533 non-null    object \n",
      " 4   combined               533 non-null    int64  \n",
      " 5   job_description_clean  533 non-null    object \n",
      " 6   Combined1              533 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 33.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 533 entries, 0 to 532\n",
      "Data columns (total 4 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   match_score           533 non-null    float64\n",
      " 1   resume                533 non-null    object \n",
      " 2   job.data.description  533 non-null    object \n",
      " 3   job.data.title        533 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 20.8+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_scored_00.info(verbose=True)\n",
    "df_scored_00 = df_scored_00[['match_score','resume','job_description_clean','job_title']]\n",
    "df_scored_00 = df_scored_00.rename(columns={'job_description_clean':'job.data.description',\n",
    "                                           'job_title':'job.data.title'})\n",
    "\n",
    "df_scored_00.info(verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b3ecd57e284f3e92a041e60668ffac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='clean', max=17.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713927600a5248c4b0d4930cfd0bc3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='stem', max=17.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of records: 533\n",
      "Total exact matches: 272\n",
      "Percent exact: 51.0%\n",
      "Percent one-half 1 off: 71.8%\n",
      "Percent Gaussian rolloff: 77.1%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>match_score</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>135</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols =['resume','job.data.description','job.data.title']\n",
    "df_scored_00['pred'] = model.predict(df_scored_00[cols])\n",
    "df_xtab = labeled_xtab(df_scored_00, labeled_col='match_score')\n",
    "d_stats = aggregate_stats_from_xtab(df_xtab)\n",
    "print_aggregate_stats(d_stats)\n",
    "display(HTML(df_xtab.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the model with the combined job title and job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/efc/unsupervised/twodimcostfidf-20200908.joblib\n"
     ]
    }
   ],
   "source": [
    "# Combined model of job summary and job descriptioin\n",
    "# https://stackoverflow.com/a/59903472/394430\n",
    "model_name = 'twodimcostfidf-20200908' ##Original model\n",
    "key  = os.path.join(model_subpath, model_name + '.joblib')\n",
    "print(key)\n",
    "from io import BytesIO\n",
    "\n",
    "with BytesIO() as data:\n",
    "    boto3.resource('s3').Bucket(s3_ds_bucket).download_fileobj(key, data)\n",
    "    data.seek(0)    # move back to the beginning after writing\n",
    "    model = joblib.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 533 entries, 0 to 532\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   match_score           533 non-null    float64\n",
      " 1   job.data.description  533 non-null    object \n",
      " 2   resume                533 non-null    object \n",
      " 3   job.data.title        533 non-null    object \n",
      " 4   combined              533 non-null    int64  \n",
      " 5   pred                  533 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 25.1+ KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0268c23f514e00bd1485db726fa9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='clean', max=17.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8f7e4a159a42e78e53f4dd583ced13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='stem', max=17.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 533 entries, 0 to 532\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   match_score           533 non-null    float64\n",
      " 1   job.data.description  533 non-null    object \n",
      " 2   resume                533 non-null    object \n",
      " 3   job.data.title        533 non-null    object \n",
      " 4   combined              533 non-null    int64  \n",
      " 5   pred                  533 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 25.1+ KB\n",
      "None\n",
      "Total number of records: 533\n",
      "Total exact matches: 275\n",
      "Percent exact: 51.6%\n",
      "Percent one-half 1 off: 71.8%\n",
      "Percent Gaussian rolloff: 77.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>match_score</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>133</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols =['resume','job.data.description','job.data.title']    \n",
    "df_scored.rename(columns={'job_title':'job.data.title', 'job_description':'job.data.description',\n",
    "                         'resume':'resume'}, inplace=True)\n",
    "df_scored.info(verbose=True)\n",
    "df_scored['pred'] = model.predict(df_scored[cols])\n",
    "\n",
    "print(df_scored.info())\n",
    "\n",
    "df_xtab = labeled_xtab(df_scored, labeled_col='match_score')\n",
    "d_stats = aggregate_stats_from_xtab(df_xtab)\n",
    "print_aggregate_stats(d_stats)\n",
    "display(HTML(df_xtab.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
